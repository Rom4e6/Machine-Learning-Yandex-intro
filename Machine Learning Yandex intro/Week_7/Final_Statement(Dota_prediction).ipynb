{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          start_time  lobby_type  r1_hero  r1_level  r1_xp  r1_gold  r1_lh  \\\n",
      "match_id                                                                     \n",
      "0         1430198770           7       11         5   2098     1489     20   \n",
      "1         1430220345           0       42         4   1188     1033      9   \n",
      "2         1430227081           7       33         4   1319     1270     22   \n",
      "3         1430263531           1       29         4   1779     1056     14   \n",
      "4         1430282290           7       13         4   1431     1090      8   \n",
      "\n",
      "          r1_kills  r1_deaths  r1_items  ...  dire_boots_count  \\\n",
      "match_id                                 ...                     \n",
      "0                0          0         7  ...                 4   \n",
      "1                0          1        12  ...                 4   \n",
      "2                0          0        12  ...                 4   \n",
      "3                0          0         5  ...                 4   \n",
      "4                1          0         8  ...                 3   \n",
      "\n",
      "          dire_ward_observer_count  dire_ward_sentry_count  \\\n",
      "match_id                                                     \n",
      "0                                2                       2   \n",
      "1                                3                       1   \n",
      "2                                3                       1   \n",
      "3                                2                       0   \n",
      "4                                3                       0   \n",
      "\n",
      "          dire_first_ward_time  duration  radiant_win  tower_status_radiant  \\\n",
      "match_id                                                                      \n",
      "0                        -52.0      2874            1                  1796   \n",
      "1                         -5.0      2463            1                  1974   \n",
      "2                         13.0      2130            0                     0   \n",
      "3                         27.0      1459            0                  1920   \n",
      "4                        -16.0      2449            0                     4   \n",
      "\n",
      "          tower_status_dire  barracks_status_radiant  barracks_status_dire  \n",
      "match_id                                                                    \n",
      "0                         0                       51                     0  \n",
      "1                         0                       63                     1  \n",
      "2                      1830                        0                    63  \n",
      "3                      2047                       50                    63  \n",
      "4                      1974                        3                    63  \n",
      "\n",
      "[5 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "#Подход 1: градиентный бустинг \"в лоб\"\n",
    "\n",
    "#1. Считайте таблицу с признаками из файла features.csv с помощью кода, приведенного выше. \n",
    "#Удалите признаки, связанные с итогами матча (они помечены в описании данных как отсутствующие в тестовой выборке).\n",
    "import time\n",
    "import datetime\n",
    "import pandas\n",
    "\n",
    "data = pandas.read_csv('./features.csv', index_col='match_id')\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "target = data['radiant_win']\n",
    "data=data.drop(columns = ['duration','radiant_win','tower_status_radiant','tower_status_dire','barracks_status_radiant','barracks_status_dire'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_blood_time               77677\n",
      "first_blood_team               77677\n",
      "first_blood_player1            77677\n",
      "first_blood_player2            53243\n",
      "radiant_bottle_time            81539\n",
      "radiant_courier_time           96538\n",
      "radiant_flying_courier_time    69751\n",
      "radiant_first_ward_time        95394\n",
      "dire_bottle_time               81087\n",
      "dire_courier_time              96554\n",
      "dire_flying_courier_time       71132\n",
      "dire_first_ward_time           95404\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#2. Проверьте выборку на наличие пропусков с помощью функции count(), которая для каждого столбца показывает число заполненных значений.\n",
    "#    Много ли пропусков в данных? Запишите названия признаков, имеющих пропуски, и попробуйте для любых двух из них дать обоснование, почему их значения могут быть пропущены.\n",
    "\n",
    "print(data.count()[data.count()!=data.shape[0]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Замените пропуски на нули с помощью функции fillna(). \n",
    "#   На самом деле этот способ является предпочтительным для логистической регрессии,\n",
    "#    поскольку он позволит пропущенному значению не вносить никакого вклада в предсказание.\n",
    "#    Для деревьев часто лучшим вариантом оказывается замена пропуска на очень большое или очень маленькое значение\n",
    "#    — в этом случае при построении разбиения вершины можно будет отправить объекты с пропусками в отдельную ветвь дерева. \n",
    "#    Также есть и другие подходы — например, замена пропуска на среднее значение признака.\n",
    "#    Мы  не требуем этого в задании, но при желании попробуйте разные подходы к обработке пропусков и сравните их между собой.\"\"\"\n",
    "\n",
    "data = data.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Какой столбец содержит целевую переменную? Запишите его название.\n",
    "#   radiant_win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6648506879750012\n",
      "0.6824618768044435\n",
      "0.6900064710388155\n",
      "0.6940387245121103\n",
      "0.6974943609466162\n",
      "Time elapsed: 0:05:27.411807\n"
     ]
    }
   ],
   "source": [
    "#5.Забудем, что в выборке есть категориальные признаки, и попробуем обучить градиентный бустинг над деревьями\n",
    "# на имеющейся матрице \"объекты-признаки\".\n",
    "# Зафиксируйте генератор разбиений для кросс-валидации по 5 блокам (KFold), не забудьте перемешать при этом выборку (shuffle=True),\n",
    "# поскольку данные в таблице отсортированы по времени, и без перемешивания можно столкнуться с нежелательными эффектами при оценивании качества.\n",
    "# Оцените качество градиентного бустинга (GradientBoostingClassifier) с помощью данной кросс-валидации,\n",
    "# попробуйте при этом разное количество деревьев (как минимум протестируйте следующие значения для количества деревьев: 10, 20, 30).\n",
    "# Долго ли настраивались классификаторы?\n",
    "# Достигнут ли оптимум на испытанных значениях параметра n_estimators, или же качество, скорее всего, продолжит расти при дальнейшем его увеличении?\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier as GBS \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle = True, random_state = 42)  \n",
    "estimators = [10,20,30,40,50]\n",
    "\n",
    "for i in estimators:\n",
    "    gbs = GBS(n_estimators=i, verbose=False, random_state=241)              # Добавить grid_search по learn_rate\n",
    "    cros_v = cross_val_score(gbs,data, target, cv = kf,scoring='roc_auc')\n",
    "    #auc = roc_auc_score(target, cros_v)\n",
    "    print(cros_v.mean())\n",
    "\n",
    "print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "# Видно, что при значении деревьев больше 30 кривая вышла на плато(изменятются только тысячные доли),\n",
    "# т.е больше брать смысла нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:39.609915\n",
      "0.6951204 {'C': 1e-05}\n",
      "0.7112501 {'C': 0.0001}\n",
      "0.7161802 {'C': 0.001}\n",
      "0.7163415 {'C': 0.01}\n",
      "0.7163101 {'C': 0.1}\n",
      "0.7163066 {'C': 1.0}\n",
      "0.7163063 {'C': 10.0}\n",
      "0.7163063 {'C': 100.0}\n",
      "0.7163063 {'C': 1000.0}\n",
      "0.7163063 {'C': 10000.0}\n",
      "0.7163063 {'C': 100000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Подход 2: логистическая регрессия\n",
    "# Линейные методы работают гораздо быстрее композиций деревьев, поэтому кажется разумным воспользоваться именно ими\n",
    "# для ускорения анализа данных. Одним из наиболее распространенных методов для классификации является логистическая регрессия.\n",
    "\n",
    "# Важно: не забывайте, что линейные алгоритмы чувствительны к масштабу признаков!\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "#1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации\n",
    "#    по той же схеме, которая использовалась для градиентного бустинга.\n",
    "#    Подберите при этом лучший параметр регуляризации (C).\n",
    "#    Какое наилучшее качество у вас получилось?\n",
    "#    Как оно соотносится с качеством градиентного бустинга?\n",
    "#    Чем вы можете объяснить эту разницу?\n",
    "#    Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "\n",
    "grid = { 'C' : np.power(10.0, np.arange(-5,6))}        # задаём название параметра для поиска максимума и границы сетки\n",
    "cv = KFold(n_splits = 5, shuffle = True, random_state = 241) \n",
    "log_reg = LogisticRegression(penalty = 'l2',  random_state=241)\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "gs = GridSearchCV(log_reg, grid, scoring = 'roc_auc', cv = cv) # \n",
    "gs.fit(data_scaled, target)\n",
    "\n",
    "print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "\n",
    "for a in gs.grid_scores_:\n",
    "    print(round(a.mean_validation_score,7),a.parameters, sep = ' ') # — оценка качества по кросс-валидации\n",
    "   # С_max= 0.01\n",
    "\n",
    "# Качество логистической регрессии выше, чем у градиентного бустинга, работает она быстрее\n",
    "# Возможно, на данном этапе это связано с заполнением пропусков, оптимальным для регрессии и масштабированием данных для неё\n",
    "# Логистическая регрессия даже с данными вида trash-in - trash-out дала преимущество над градиентным бустингом. \n",
    "# Если посмотреть честно - мы сталкивали градиентный классификатор с линейным регрессором.\n",
    "# В документации GBС сказано, что при выборе функции потерь \"по умолчанию\" он ведёт себя как логистическая регрессия, \n",
    "# пусть и с другим методом оптимизации. Таким образом, мы стравливаем нормальную логистическую регрессию, под которую оптимизируем датасет,\n",
    "#                                                           с костыльно работающим градиентным бустингом. \n",
    "# Возможно, в случае более удачного подбора параметров, градиентный бустинг одержал бы верх."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:02:06.716869\n",
      "0.6950569 {'C': 1e-05}\n",
      "0.7112484 {'C': 0.0001}\n",
      "0.7162356 {'C': 0.001}\n",
      "0.716401 {'C': 0.01}\n",
      "0.7163738 {'C': 0.1}\n",
      "0.7163708 {'C': 1.0}\n",
      "0.7163705 {'C': 10.0}\n",
      "0.7163705 {'C': 100.0}\n",
      "0.7163705 {'C': 1000.0}\n",
      "0.7163705 {'C': 10000.0}\n",
      "0.7163705 {'C': 100000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#    2. Среди признаков в выборке есть категориальные, которые мы использовали как числовые, что вряд ли является хорошей идеей. \n",
    "#        Категориальных признаков в этой задаче одиннадцать: lobby_type и r1_hero, r2_hero, ..., r5_hero, d1_hero, d2_hero, ..., d5_hero.\n",
    "#        Уберите их из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации.\n",
    "#        Изменилось ли качество? Чем вы можете это объяснить?\n",
    "\n",
    "data_drop_cat=data.drop(columns = ['lobby_type','r1_hero','r2_hero','r3_hero','r4_hero','r5_hero','d1_hero','d2_hero','d3_hero','d4_hero','d5_hero'],axis=1)\n",
    "data_drop_cat_scaled=scaler.fit_transform(data_drop_cat) # изменили раземрность датафрейма, fit заново\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "gs.fit(data_drop_cat_scaled, target) #gs.fit(data_drop_cat_scaled, target) #\n",
    "\n",
    "\n",
    "print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "for a in gs.grid_scores_:\n",
    "    print(round(a.mean_validation_score,7),a.parameters, sep = ' ') # — оценка качества по кросс-валидации\n",
    "   # С_max= 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "#3. На предыдущем шаге мы исключили из выборки признаки rM_hero и dM_hero, которые показывают,\n",
    "#   какие именно герои играли за каждую команду.\n",
    "#   Это важные признаки — герои имеют разные характеристики, и некоторые из них выигрывают чаще, чем другие.\n",
    "#   Выясните из данных, сколько различных идентификаторов героев существует в данной игре (вам может пригодиться фукнция unique или value_counts).\n",
    "labels = ['r1_hero','r2_hero','r3_hero','r4_hero','r5_hero','d1_hero','d2_hero','d3_hero','d4_hero','d5_hero']\n",
    "for i in labels:\n",
    "    print(len(pandas.unique(data[i])))\n",
    "N = len(pandas.unique(data[i])) # Возможно, произошла магия, но N = 112. \n",
    "                                # При этом всего 108 персонажей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3    4    5    6    7    8    9    ...  102  103  104  \\\n",
      "0      0.0  0.0  0.0 -1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  1.0   \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0 -1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "2      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "97225  1.0  0.0 -1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "97226  0.0  0.0  0.0  1.0 -1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "97227  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "97228  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0  0.0  ...  0.0  0.0  0.0   \n",
      "97229  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
      "\n",
      "       105  106  107  108  109  110  111  \n",
      "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  \n",
      "97225  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "97226  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "97227  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "97228 -1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
      "97229 -1.0  0.0  0.0  0.0  0.0  0.0 -1.0  \n",
      "\n",
      "[97230 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "#4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях.\n",
    "#    Пусть всего в игре имеет N различных героев.\n",
    "#    Сформируем N признаков, при этом i-й будет равен нулю, если i-й герой не участвовал в матче;\n",
    "#    единице, если i-й герой играл за команду Radiant;\n",
    "#    минус единице, если i-й герой играл за команду Dire.\n",
    "#    Ниже вы можете найти код, который выполняет данной преобразование.\n",
    "#    Добавьте полученные признаки к числовым, которые вы использовали во втором пункте данного этапа.\n",
    "\n",
    "\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in range(5):\n",
    "        X_pick[i, data.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pick_df = pandas.DataFrame(X_pick)\n",
    "\n",
    "#print(X_pick_df) # Видим, что автоматически нумерация стартует с 0. Нумерация персонажей начинается с единицы, учтём это:\n",
    "\n",
    "X_pick_df.columns = range(1,N+1)\n",
    "\n",
    "#print(X_pick_df)\n",
    "\n",
    "cols = [col for col in X_pick_df.columns if col in heroes] # Всего 112 столбцов и 108 героев. Какие-то лишние. Уберём их.\n",
    "\n",
    "X_pick_df = X_pick_df[cols] \n",
    "\n",
    "#print(X_pick_df)\n",
    "\n",
    "data_drop_cat_scaled = pandas.DataFrame(data_drop_cat_scaled)\n",
    "data_bag_words = pandas.concat([data_drop_cat_scaled, X_pick_df], axis = 1) # Горизонтальная склейка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0:04:22.501979\n",
      "0.6991713 {'C': 1e-05}\n",
      "0.7250221 {'C': 0.0001}\n",
      "0.7462962 {'C': 0.001}\n",
      "0.751736 {'C': 0.01}\n",
      "0.7519374 {'C': 0.1}\n",
      "0.7519196 {'C': 1.0}\n",
      "0.7519174 {'C': 10.0}\n",
      "0.751917 {'C': 100.0}\n",
      "0.751917 {'C': 1000.0}\n",
      "0.751917 {'C': 10000.0}\n",
      "0.7519172 {'C': 100000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#5.    Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации.\n",
    "#     Какое получилось качество?\n",
    "#     Улучшилось ли оно?\n",
    "#     Чем вы можете это объяснить?\n",
    "\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    " \n",
    "gs.fit(data_bag_words, target)\n",
    "\n",
    "print ('Time elapsed:', datetime.datetime.now() - start_time)\n",
    "\n",
    "for a in gs.grid_scores_:\n",
    "    print(round(a.mean_validation_score,7),a.parameters, sep = ' ') # — оценка качества по кросс-валидации\n",
    "   # С_max= 0.1 Таки изменился. Не зря просили ещё раз gridsearch сделать\n",
    "\n",
    "#   Качество модели значительно возросло при добавлении категориальных признаков в удобоваримом виде,\n",
    "#                                                                         что свидетельствует об их важности\n",
    "#                               Т.е от выбранных персонажей во многом зависит исход сражения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#6.  Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей\n",
    "#    (лучшей с точки зрения AUC-ROC на кросс-валидации).\n",
    "#    Убедитесь, что предсказанные вероятности адекватные — находятся на отрезке [0, 1], не совпадают между собой\n",
    "#    (т.е. что модель не получилась константной).\n",
    "\n",
    "test = pandas.read_csv('./features_test.csv', index_col='match_id')\n",
    "#print(test)\n",
    "test = test.fillna(0)\n",
    "test_drop_cat=test.drop(columns = ['lobby_type','r1_hero','r2_hero','r3_hero','r4_hero','r5_hero','d1_hero','d2_hero','d3_hero','d4_hero','d5_hero'],axis=1)\n",
    "test_drop_cat_scaled = scaler.transform(test_drop_cat) # Есть уже обученный scaler для дропнутых категориальных признаков\n",
    "test_drop_cat_scaled = pandas.DataFrame(test_drop_cat_scaled)\n",
    "test_pick = np.zeros((test.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(test.index):\n",
    "    for p in range(5):\n",
    "        test_pick[i, test.ix[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        test_pick[i, test.ix[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "\n",
    "test_pick_df = pandas.DataFrame(test_pick)\n",
    "test_pick_df.columns = range(1,N+1)\n",
    "cols = [col for col in test_pick_df.columns if col in heroes]\n",
    "test_pick_df = test_pick_df[cols] \n",
    "test_drop_cat_scaled = pandas.DataFrame(test_drop_cat_scaled)\n",
    "test_bag_words = pandas.concat([test_drop_cat_scaled, test_pick_df], axis = 1)\n",
    "pred = gs.predict_proba(test_bag_words)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9963714245178639 0.008428978265274441 0.5170234016735038\n"
     ]
    }
   ],
   "source": [
    "print(max(pred), min(pred), pred.mean())\n",
    "#Получили адекватно выглядещее распределение вероятности - максимально возможное - близко к 1, минимальное - почти 0, среднее 1/2\n",
    "# Распределение типа \"Колокол\". Возможно, и гауссово, но доказывать это не будем :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
